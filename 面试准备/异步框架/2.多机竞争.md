## 1. 实现的2种方案

1. For the same batch of data, use **Row-Level Lock**, but it may caused
   - **Gap Lock**;
     - 现象：拉取任务时，有些任务会直接 fail / success
   - Potential **High CPU Usage**;
     - 现象：在压力测试中，每个worker拉取500个任务，就能看到CPU占用会突然提升
     - 原理：By Default, MySQL will **detect the dead-lock**；即，Is there any **dependency for same resource** among **threads**; (M个线程，获取N个任务，就是 O(M*N))
2. **Distribution Lock**, who get the lock, who get the task
   - 缺点：冲突时，其它Aaron会**闲置**；此外，如果锁释放有问题，释放**晚了**，也会有Aaron闲置；
   - 如果有很多Aaron，抢一个锁，会浪费资源；

## 2. 更加完善的方案

引入一个中间层，利用 Kafka的 **Partitions**，来放置拉取到的任务；单个Aaron**监听**某一个topic的**分区**即可；

<img src="/Users/aaron/Desktop/SDE/面试准备/异步框架/assets/image-20240904140816833.png" alt="image-20240904140816833" style="zoom:50%;" />

1. 因为我在Eth Technology的实习中，接触了Kafka，并使用kafka完成了一个 Streaming Microservice. 我注意到了 Multi-Partition Features, 于是想要利用这个分区，来解决冲突问题；



## 补充知识

**MySQL间隙锁 GAP LOCK**: 假设我们有 4个任务 (3个待执行, 1个执行中，他们都是 **state=1**)

- 如果我们对 待执行的任务, 使用**for-update 行级锁**进行**批量的选中** (where state = 1 for update);
- 此时, 任务4：set state = **2**!!!， **正在执行中**
- 这个 任务4 **就会被阻塞!**
- 因为: 
  1. Update = Delete + Insert (两个阶段)
  2. Delete完成后, 要Insert一个**待执行**的数据, 就会被 **这个for-update带来的 间隙锁 造成的阻塞**;
- 为什么会有 **间隙锁**?
  因为这是一个 *批量的选中* (官方名: **非唯一索引**)