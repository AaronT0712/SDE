**Tell me about a time you solved a pain point for the team** (for-loop导入太慢，concurrent + pool加速，每次开发完数据库相关的功能就会慢)

**Situation:**
During my internship as an SDE intern, we were building a partner matching platform based on a user system. We had successfully completed the user query function, and to test the system’s performance, we needed to simulate an environment with 10 million users. However, the existing data import process provided by the software was extremely slow. Considering that we would frequently repeat this process in the future, this could become a major bottleneck and hinder our development progress.

**Task:**
As a member of the backend team, I wanted to o optimize the data import process to ensure it wouldn't slow down our testing or future development. So, I am focused on looking into this problem, figuring out a better practice, and  them implemented this solutions that allow to quickly import data. 

**Action:**

+ Because the bulit-in function was too slow, so I decided to implement by my own. After I found that the bulit-in function do the insertion one by one, I first used Batch Insertion, which improved the speed greatly.
  However, I realized that if one of the loop insertion takes too long or fail, it would block or negatively impact the following batch insertions.

- To address this, I decided to threads to do batch insertion. The idea was to process multiple batches concurrently so that these can reduce the time.
   But it seems that the improvement didn't not meet the requirement.
- After analyzing and testing, I found that this issue came from thread pool configuration. I then using a custom thread pool to ensure each thread was active and performing the batch insertion.

**Result:**
The optimization resulted in a sixfold increase in data import speed. This substantial improvement not only resolved the immediate bottleneck but also accelerated our overall development and testing phases, making it easier for the team to simulate large datasets efficiently.